{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"test.jpg\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> **Finding lane lines:** Use the code below identify the lane lines in this image.</p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding up a Color Selection\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image is:  <class 'numpy.ndarray'> with dimesions: (540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib qt\n",
    "\n",
    "image = mpimg.imread('test.jpg')\n",
    "print('This image is: ',type(image), \n",
    "         'with dimesions:', image.shape)\n",
    "ysize = image.shape[0]\n",
    "xsize = image.shape[1]\n",
    "\n",
    "plt.imshow(image)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play with the color selection (modify “redCut, greenCut, blueCut”) until you are able to retain as much of the lines as possible, while getting rid of most of the other stuff.  Check that your output \"colorSel\" looks roughly like the example image in the lesson.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colorSel = np.copy(image)\n",
    "\n",
    "redCut =0\n",
    "greenCut = 0\n",
    "blueCut = 0\n",
    "rgbThresh = [redCut, greenCut, blueCut]\n",
    "\n",
    "for xpos in range(xsize):\n",
    "    for ypos in range(ysize):\n",
    "        red = image[ypos, xpos, 0]\n",
    "        green = image[ypos, xpos, 1]\n",
    "        blue = image[ypos, xpos, 2]\n",
    "        if red < rgbThresh[0] or green <  rgbThresh[1] or blue < rgbThresh[2]:\n",
    "            colorSel[ypos, xpos, :] = [0, 0, 0]\n",
    "\n",
    "plt.imshow(colorSel)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"color_selected.jpg\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look approximately like this after color selection and region masking </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Coding up a Region of Interest Mask\n",
    "===\n",
    "\n",
    "** Now try to mask out everything but the region of interest in the image (where the lane lines are).  Play around with the variables \"leftBottom\", \"rightBottom\", and \"apex\" until your triangular mask looks similar to the example image below. Note that the y axis goes from 0 at the top, to 539 at the bottom of the image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regionSel = np.copy(image)\n",
    "\n",
    "#defining a triangle region of interest\n",
    "leftBottom = [0,539]\n",
    "rightBottom = [900,539]\n",
    "apex = [480,0]\n",
    "\n",
    "\n",
    "fitLeft = np.polyfit((leftBottom[0], apex[0]), (leftBottom[1], apex[1]), 1)\n",
    "fitRight = np.polyfit((rightBottom[0], apex[0]), (rightBottom[1], apex[1]), 1)\n",
    "\n",
    "\n",
    "for xpos in range(xsize):\n",
    "    for ypos in range(ysize):\n",
    "        if ypos < (fitLeft[0]*xpos + fitLeft[1]) or ypos < (fitRight[0]*xpos + fitRight[1]):\n",
    "            regionSel[ypos, xpos, :] = [0, 0, 0]\n",
    "\n",
    "plt.imshow(regionSel)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"masked.jpg\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look approximately like this after region masking </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining Color and Region Selections\n",
    "===\n",
    "\n",
    "**Now lets combine the mask and color selection to get only the lane lines out of the image.**  \n",
    "\n",
    "**Check out the code below.  Here we’re doing both steps in the same nested for loop, requiring that a pixel meet both the mask and color selection requirements to be retained.**\n",
    "\n",
    "**Your color selection plus mask should now look like the first  sample image.  We also painted the lines back onto our original image to see how they look.  Compare your result with the second sample image.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colorSel = np.copy(image)\n",
    "\n",
    "fitLeft = np.polyfit((leftBottom[0], apex[0]), (leftBottom[1], apex[1]), 1)\n",
    "fitRight = np.polyfit((rightBottom[0], apex[0]), (rightBottom[1], apex[1]), 1)\n",
    "lineImage = np.copy(image)\n",
    "\n",
    "for xpos in range(xsize):\n",
    "    for ypos in range(ysize):\n",
    "        red = image[ypos, xpos, 0]\n",
    "        green = image[ypos, xpos, 1]\n",
    "        blue = image[ypos, xpos, 2]\n",
    "        if red < rgbThresh[0] or green <  rgbThresh[1] or blue < rgbThresh[2]:\n",
    "            colorSel[ypos, xpos, :] = [0, 0, 0]\n",
    "        elif ypos < (fitLeft[0]*xpos + fitLeft[1]) or ypos < (fitRight[0]*xpos + fitRight[1]):\n",
    "            colorSel[ypos, xpos, :] = [0, 0, 0]\n",
    "        else: \n",
    "            lineImage[ypos, xpos, :] = [255, 0, 0]\n",
    "\n",
    "plt.imshow(colorSel)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"color_roi_sel.png\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look approximately like this after color selection and region masking </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the cell below to paint the lines on the road**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(lineImage)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"redLines.png\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look approximately like this after color selection and region masking </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canny Edge Detection in Action\n",
    "===\n",
    "\n",
    "**Read in the image below and play with the parameters to detect edges using Canny**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = mpimg.imread('mountain_road.jpg')\n",
    "plt.imshow(image)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"mountain_road.jpg\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernelSize = 5\n",
    "blurGray = cv2.GaussianBlur(gray,(kernelSize, kernelSize),0)\n",
    "\n",
    "lowThreshold = 10\n",
    "highThreshold = 50\n",
    "apSize = 5\n",
    "edges = cv2.Canny(blurGray, lowThreshold, highThreshold, apertureSize = apSize)\n",
    "\n",
    "plt.imshow(edges, cmap='Greys_r')\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    " <img src=\"edgymountain.jpg\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look approximately like this after edge detection </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing a Hough Transform on Edge Detected Image\n",
    "===\n",
    "\n",
    "**Play with the parameteres for the Hough Transform to find lines below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the Hough transform takes various parameters\n",
    "#see the links above to learn more about what they do.\n",
    "rho = 1\n",
    "theta = np.pi/180\n",
    "threshold = 1\n",
    "minLineLength = 10\n",
    "maxLineGap = 3\n",
    "lineImage = np.copy(image)*0 #creating a blank to draw lines on\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n",
    "                            minLineLength, maxLineGap)\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(lineImage,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "\n",
    "colorEdges = np.dstack((edges, edges, edges))\n",
    "combo = cv2.addWeighted(colorEdges, 0.8, lineImage, 1, 0)\n",
    "\n",
    "\n",
    "plt.imshow(combo)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<figure>\n",
    " <img src=\"hough_mountain.jpg\" width=\"480\" alt=\"Color Selected Image\" />\n",
    " <p/>\n",
    " <figcaption>\n",
    " <p></p> \n",
    " <p style=\"text-align: center;\"> Your output image should look approximately like this after line detection </p> \n",
    " </figcaption>\n",
    "</figure>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
