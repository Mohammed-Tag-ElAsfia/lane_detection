{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (540, 960, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"In this project, we'll learn to identify the lines on the road that identify where the\n",
    "lane is.  We'll practice first on a single image, and later apply our tools to a video \n",
    "stream (really just a series of images. \"\"\"\n",
    "\n",
    "#let's have a look at our test image called 'test.jpg'\n",
    "#note: you can run the current cell by hitting \"Shift-Enter\" \n",
    "#or the play button in the toolbar above\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib qt\n",
    "\n",
    "image = mpimg.imread('test.jpg')\n",
    "print(type(image), image.shape)\n",
    "plt.imshow(image)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Have a look at the test image. With our eyes, we can easily identify the lane lines right?\n",
    "So let's brainstorm ways we might be able to identify them with an algorithm... \n",
    "what kind of features do you think\n",
    "we could use to identify the lane lines in the image?\n",
    "\n",
    "To start with, we're going to go with color as a major identifier of the lines, because they're white, and most of\n",
    "the pixels in the image are some other color.  We have our image stored in the variable 'image', which is an array \n",
    "with shape (y, x, color depth) = (540, 960, 3).  Hence this is a 540 by 960 pixel 3 color image containing values for each\n",
    "of Red, Green, and Blue (RGB).  Use the interactive matplotlib window (or whatever tools you like) to explore \n",
    "the colors of the lane lines themselves.  We'll use this to get rid of pixels in the image which do not fall \n",
    "into this range. \n",
    "\n",
    "(upon doing this exercise, we find the [R, G, B] range is something like [165, 165, 165] to [245, 245, 245])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"next we'll define a function to select only the pixels within our color range for an image\"\"\"\n",
    "\n",
    "#HERE THE STUDENT WILL DETERMINE THE COLOR RANGE BY PLAYING WITH THE TEST IMAGE IN MATPLOTLIB OR SIMILAR\n",
    "\n",
    "def color_select(image, white_low, white_high):\n",
    "    lower_white = np.array(white_low, dtype=np.uint8) #student fills in the numbers here\n",
    "    upper_white = np.array(white_high, dtype=np.uint8) #student fills in the numbers here\n",
    "    selected = cv2.inRange(image, lower_white, upper_white)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Now we'll operate on the image and see what we get.  We'll also start using OpenCV to look at images.  The\n",
    "result should pop up in a separate window\"\"\"\n",
    "white_low = [200, 200, 200]\n",
    "white_high = [255, 255, 255]\n",
    "cselect = color_select(image, white_low, white_high)\n",
    "plt.imshow(cselect, cmap='Greys_r')\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Your output color selected image should look approximately like the sample color selected image.\n",
    "\n",
    "We have now drastically simplified our image to contain binary values (0 or 255), where zeros correspond to pixels\n",
    "that did not fall within the specified color range.  All the remaining pixels were similar in color to the lane lines.\n",
    "We observe that, while the lane lines themselves are clearly visible, there are still a lot of other pixels, \n",
    "particularly in the sky portion of the frame, remaining.\n",
    "\n",
    "At this point we will use to our advantage, the fact that we know the lane lines we're interested in only appear on\n",
    "the road, so we can mask out portions of the image that are not relevant to our search.  To do this, we'll define a \n",
    "couple more funtions:\"\"\"\n",
    "\n",
    "#HERE THE STUDENT WILL DETERMINE THE REGION OF INTEREST\n",
    "\n",
    "#first just a convenience function that just returns a blank image the same size as the one we're working with\n",
    "def blank(image):\n",
    "    rows,cols = image.shape[:2]\n",
    "    if len(image.shape) == 2:\n",
    "        return np.zeros((rows, cols), np.uint8)\n",
    "    else:\n",
    "        return np.zeros((rows, cols, 3), np.uint8)\n",
    "    \n",
    "#second, a function that returns the Region of Interest, which is cropped image that no longer \n",
    "#contains areas we aren't interested in.\n",
    "#in this case, we're throwing out the top 40% of the image, but keeping all the width\n",
    "\n",
    "def RegionOfInterest(image, bottomPerc, topPerc, leftPerc, rightPerc):\n",
    "    rows,cols = image.shape[:2]\n",
    "    copy = image.copy()\n",
    "    z = blank(image)\n",
    "    copy[:round(rows*topPerc),:] = z[:round(rows*topPerc),:]\n",
    "    copy[round(rows*bottomPerc):,:] = z[round(rows*bottomPerc):,:]\n",
    "    copy[:,:round(cols*leftPerc)] = z[:,:round(cols*leftPerc)]\n",
    "    copy[:,round(cols*rightPerc):] = z[:,round(cols*rightPerc):]\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets operate on our color selected image and see what we get\n",
    "bottomPerc = 1.\n",
    "topPerc = 0.675\n",
    "leftPerc = 0.2\n",
    "rightPerc = 0.8\n",
    "focus = RegionOfInterest(cselect, bottomPerc, topPerc, leftPerc, rightPerc)\n",
    "plt.imshow(focus, cmap='Greys_r')\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Ok, now we've got some nice lines to detect!  Next, we'll apply a Hough Transform to find lines in our \n",
    "edge-detected image.  The Hough transform can be used to detect various shapes in an image, but here we'll\n",
    "use it to detect lines (more on the 'how' to come...  We'll write another couple functions here to perform \n",
    "the Hough transform and then draw the detected lines back onto our original image.\"\"\"\n",
    "\n",
    "#HERE THE STUDENT WILL NEED TO PLAY WITH THE HOUGH TRANSFORM PARAMETERS TO GET A REASONABLE RESULT\n",
    "\n",
    "def houghLinesP(image, edges):\n",
    "    minLineLength = 25\n",
    "    maxLineGap = 10 \n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,10,minLineLength,maxLineGap)\n",
    "    drawLane(image, lines)\n",
    "    return lines\n",
    "    \n",
    "def drawLane(image, lines):\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(image,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "    return\n",
    "\n",
    "\n",
    "hough = blank(image)\n",
    "lines = houghLinesP(hough, focus)\n",
    "lineImage = cv2.bitwise_or(image, RegionOfInterest(hough, bottomPerc, topPerc, leftPerc, rightPerc))\n",
    "plt.imshow(lineImage)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWOqS1BBLXZIaYqlLUkP+D2PwbQ6bLyluAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1109894e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Ok, now we've got some nice line detections!  Clearly, some of the detections are our lane lines, but we've\n",
    "picked up some other stuff as well.  Now we need to figure out how to select lane lines only from detected lines\n",
    "and plot out the full lane on the image.  To do this let's start by investigating the slope of the lines\"\"\"\n",
    "\n",
    "#our output 'lines' from above contains the x and y endpoints of all detected lines\n",
    "#we'll use matplotlib to look at the slope distribution\n",
    "\n",
    "#HERE THE STUDENT WILL NEED TO LOOK AT THE SLOPE HISTOGRAM (OR WHATEVER ELSE THEY LIKE) AND DETERMINE A SLOPE CUTOFF\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x1,y1,x2,y2 = lines[:,0,0], lines[:,0,1], lines[:,0,2], lines[:,0,3]\n",
    "slopes = (y2-y1)/(x2-x1) #rise over run\n",
    "\n",
    "slope_hist = plt.hist(slopes)\n",
    "#note the three distinct bins in slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Ok, so we've got slopes concentrated around 3 values, namely, around 0, and +/- 0.8.  We could investigate\n",
    "deeper, but just looking at the image we can see that most of the stuff we don't want are probably the \n",
    "concentration of slope values near 0.  So lets impose a restriction on which lines we're going to draw based\n",
    "on slope... To do this we'll redefine our drawLane function\"\"\"\n",
    "\n",
    "hiSlopeCut = 0.6 #student will change this value\n",
    "loSlopeCut = -0.4 #student will change this value\n",
    "\n",
    "def drawLane(image, lines):\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                rise = y2 - y1\n",
    "                run = x2 - x1\n",
    "                if run != 0:\n",
    "                    slope = float(rise / run)\n",
    "                    if slope > hiSlopeCut or slope < loSlopeCut:\n",
    "                        cv2.line(image,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "    return\n",
    "\n",
    "hough = blank(image)\n",
    "lines = houghLinesP(hough, focus)\n",
    "lineImage = cv2.bitwise_or(image, RegionOfInterest(hough, bottomPerc, topPerc, leftPerc, rightPerc))\n",
    "\n",
    "%matplotlib qt\n",
    "plt.imshow(lineImage)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"So, now we've got our lane lines identified, and we'd like to draw an estimate of where the \n",
    "lane is on the image.  To do this, fit a line to to all \n",
    "the detected line segments, and extrapolate up and \n",
    "down the road. Again, we'll redefine our \n",
    "drawLanes function\n",
    "and our houghLinesP to include one more parameter...\"\"\"\n",
    "\n",
    "#HERE I'M NOT SURE WHAT TO HAVE THE STUDENT DO, BUT MAYBE FIGURE OUT THEIR OWN WAY OF DRAWING THE LINES BETTER\n",
    "\n",
    "def drawLane(image, lines):\n",
    "    \n",
    "    midpointx = round(float(image.shape[1])/2)\n",
    "    rightX = []\n",
    "    leftX = []\n",
    "    rightY = []\n",
    "    leftY = []\n",
    "       \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                rise = y2 - y1\n",
    "                run = x2 - x1\n",
    "                if run != 0:\n",
    "                    slope = float(rise / run)                \n",
    "                    if slope > hiSlopeCut and x1 > midpointx and x2 > midpointx: \n",
    "                        #identifying lane line segments on the right side of the frame\n",
    "                        rightX.extend([x1, x2])\n",
    "                        rightY.extend([y1, y2])\n",
    "                    elif slope < loSlopeCut and x1 < midpointx and x2 < midpointx: \n",
    "                        #identifying lane line segments on the left side of the frame\n",
    "                        leftX.extend([x1, x2])\n",
    "                        leftY.extend([y1, y2])                   \n",
    "\n",
    "        if leftX and leftY:\n",
    "            fitLeft = np.polyfit(leftX, leftY, 1)\n",
    "            startYleft = 0\n",
    "            endYleft = image.shape[0]\n",
    "            startXleft = int((startYleft - fitLeft[1]) / fitLeft[0])\n",
    "            endXleft = int((endYleft - fitLeft[1]) / fitLeft[0])\n",
    "            cv2.line(image,(startXleft,startYleft),(endXleft,endYleft),(0,0,255),10)\n",
    "            \n",
    "        if rightX and rightY:\n",
    "            fitRight = np.polyfit(rightX, rightY, 1)\n",
    "            startYright = 0\n",
    "            endYright = image.shape[0]\n",
    "            startXright = int((startYright - fitRight[1]) / fitRight[0])\n",
    "            endXright = int((endYright - fitRight[1]) / fitRight[0])\n",
    "            cv2.line(image,(startXright,startYright),(endXright,endYright),(0,0,255),10)\n",
    "        \n",
    "        \n",
    "\n",
    "hough = blank(image)\n",
    "lines = houghLinesP(hough, focus)\n",
    "lineImage = cv2.bitwise_or(image, RegionOfInterest(hough, bottomPerc, topPerc, leftPerc, rightPerc))\n",
    "\n",
    "plt.imshow(lineImage)\n",
    "fig = plt.gcf()\n",
    "fig.canvas.manager.window.raise_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Ok awesome!  We're mapping out the lane!  Now let's try it on a video stream. To do this, let's gather all \n",
    "the code into one place so this cell can be run independent of the rest of the notebook, or copied and pasted\n",
    "to somewhere else.  Ok gonna run the video now and see what happens!\"\"\"\n",
    "\n",
    "#HERE AGAIN, NOT SURE WHAT TO HAVE THE STUDENT DO, BUT IF THIS IS AN EVALUATED PROJECT, THEY COULD SUBMIT\n",
    "#SUGGESTIONS ABOUT HOW TO IMPROVE THE ALGORITHM.  \n",
    "# now we're going to run the whole thing\n",
    "   \n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow('Lane-Finding')\n",
    "cap = cv2.VideoCapture('Highway_Driving.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, image = cap.read()\n",
    "    if image is not None:\n",
    "        cselect = color_select(image, white_low, white_high)\n",
    "        focus = RegionOfInterest(cselect, bottomPerc, topPerc, leftPerc, rightPerc)\n",
    "        hough = blank(image)\n",
    "        houghLinesP(hough, focus)\n",
    "        final = cv2.bitwise_or(image, RegionOfInterest(hough, bottomPerc, topPerc, leftPerc, rightPerc))\n",
    "        cv2.imshow('Lane-Finding',final)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27 :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "# that was a demonstration of lane finding in OpenCV!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Fantastic!  It kinda works!  Clearly, however, our algorithm is still a bit unstable and could use \n",
    "further improvement.  So things to think about going forward are: how can we stabilize the lane detection \n",
    "further?  Where does it fail the worst?  What will we need to take into account going forward \n",
    "with lane detection?  Pretty cool huh?  We're actually detecting lane lines!  This could work afterall\n",
    "\n",
    "Lets see if we can improve this with edge detection... and shape detection lane finding\n",
    "in opencv  This may actually work afterall!  still a bit unstable.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
