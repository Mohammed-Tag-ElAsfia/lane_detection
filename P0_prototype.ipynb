{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (540, 960, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115a07c18>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"In this project, we'll learn to identify lane lines in a video stream.  A video stream is really just\n",
    "a bunch of images, so we'll begin by looking at just one image from the video.  We'll set up our \n",
    "algorithm by finding the lane lines in this one image, then apply it to the video.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#let's have a look at our test image called 'test.jpg'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib qt\n",
    "\n",
    "image = mpimg.imread('test.jpg')\n",
    "print(type(image), image.shape)\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Have a look at the test image. With our eyes, we can easily identify the lane lines right?  So let's \n",
    "brainstorm ways we might be able to identify them with an algorithm... what kind of features do you think\n",
    "we could use to identify the lane lines in the image?\n",
    "\n",
    "To start with, we're going to go with color as a major identifier of the lines, because they're white, and most of\n",
    "the pixels in the image are some other color.  We have our image stored in the variable 'image', which is an array \n",
    "with shape (y, x, color depth) = (540, 960, 3).  Hence this is a 540 by 960 pixel 3 color image containing values for each\n",
    "of Red, Green, and Blue (RGB).  Use the interactive matplotlib window (or whatever tools you like) to explore \n",
    "the colors of the lane lines themselves.  We'll use this to get rid of pixels in the image which do not fall \n",
    "into this range. \n",
    "\n",
    "(upon doing this exercise, we find the [R, G, B] range is something like [165, 165, 165] to [245, 245, 245])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"next we'll define a function to select only the pixels within our color range for an image\"\"\"\n",
    "\n",
    "#HERE THE STUDENT WILL DETERMINE THE COLOR RANGE BY PLAYING WITH THE TEST IMAGE IN MATPLOTLIB OR SIMILAR\n",
    "\n",
    "def color_select(image):\n",
    "    lower_white = np.array([165,165,165], dtype=np.uint8) #student fills in the numbers here\n",
    "    upper_white = np.array([245,245,245], dtype=np.uint8) #student fills in the numbers here\n",
    "    selected = cv2.inRange(image, lower_white, upper_white)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11cd4ac18>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Now we'll operate on the image and see what we get.  We'll also start using OpenCV to look at images.  The\n",
    "result should pop up in a separate window\"\"\"\n",
    "cselect = color_select(image)\n",
    "plt.imshow(cselect, cmap='Greys_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Your output color selected image should look approximately like the sample color selected image.\n",
    "\n",
    "We have now drastically simplified our image to contain binary values (0 or 255), where zeros correspond to pixels\n",
    "that did not fall within the specified color range.  All the remaining pixels were similar in color to the lane lines.\n",
    "We observe that, while the lane lines themselves are clearly visible, there are still a lot of other pixels, \n",
    "particularly in the sky portion of the frame, remaining.\n",
    "\n",
    "At this point we will use to our advantage, the fact that we know the lane lines we're interested in only appear on\n",
    "the road, so we can mask out portions of the image that are not relevant to our search.  To do this, we'll define a \n",
    "couple more funtions:\"\"\"\n",
    "\n",
    "#HERE THE STUDENT WILL DETERMINE THE REGION OF INTEREST\n",
    "\n",
    "#first just a convenience function that just returns a blank image the same size as the one we're working with\n",
    "def blank(image):\n",
    "    rows,cols = image.shape[:2]\n",
    "    if len(image.shape) == 2:\n",
    "        return np.zeros((rows, cols), np.uint8)\n",
    "    else:\n",
    "        return np.zeros((rows, cols, 3), np.uint8)\n",
    "    \n",
    "#second, a function that returns the Region of Interest or 'ROI', which is cropped image that no longer \n",
    "#contains areas we aren't interested in.\n",
    "#in this case, we're throwing out the top 40% of the image, but keeping all the width\n",
    "\n",
    "def roi(image):\n",
    "    rows,cols = image.shape[:2]\n",
    "    copy = image.copy()\n",
    "    z = blank(image)\n",
    "    copy[:round(rows*0.4),:] = z[:round(rows*0.4),:]\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11cd4aba8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets operate on our color selected image and see what we get\n",
    "focus = roi(cselect)\n",
    "plt.imshow(focus, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1126cf828>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Ok, now we've got some nice lines to detect!  Next, we'll apply a Hough Transform to find lines in our \n",
    "edge-detected image.  The Hough transform can be used to detect various shapes in an image, but here we'll\n",
    "use it to detect lines (more on the 'how' to come...  We'll write another couple functions here to perform \n",
    "the Hough transform and then draw the detected lines back onto our original image.\"\"\"\n",
    "\n",
    "#HERE THE STUDENT WILL NEED TO PLAY WITH THE HOUGH TRANSFORM PARAMETERS TO GET A REASONABLE RESULT\n",
    "\n",
    "def houghLinesP(image, edges):\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 10 \n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,10,minLineLength,maxLineGap)\n",
    "    drawLane(image, lines)\n",
    "    return lines\n",
    "    \n",
    "def drawLane(image, lines):\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                cv2.line(image,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "    return\n",
    "\n",
    "\n",
    "hough = blank(image)\n",
    "lines = houghLinesP(hough, focus)\n",
    "lineImage = cv2.bitwise_or(image, roi(hough))\n",
    "plt.imshow(lineImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEACAYAAABMEua6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a47b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Ok, now we've got some nice line detections!  Clearly, some of the detections are our lane lines, but we've\n",
    "picked up some other stuff as well.  Now we need to figure out how to select lane lines only from detected lines\n",
    "and plot out the full lane on the image.  To do this let's start by investigating the slope of the lines\"\"\"\n",
    "\n",
    "#our output 'lines' from above contains the x and y endpoints of all detected lines\n",
    "#we'll use matplotlib to look at the slope distribution\n",
    "\n",
    "#HERE THE STUDENT WILL NEED TO LOOK AT THE SLOPE HISTOGRAM (OR WHATEVER ELSE THEY LIKE) AND DETERMINE A SLOPE CUTOFF\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x1,y1,x2,y2 = lines[:,0,0], lines[:,0,1], lines[:,0,2], lines[:,0,3]\n",
    "slopes = (y2-y1)/(x2-x1) #rise over run\n",
    "\n",
    "slope_hist = plt.hist(slopes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11fff12e8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Ok, so we've got slopes concentrated around 3 values, namely, around 0, and +/- 0.8.  We could investigate\n",
    "deeper, but just looking at the image we can see that most of the stuff we don't want are probably the \n",
    "concentration of slope values near 0.  So lets impose a restriction on which lines we're going to draw based\n",
    "on slope... To do this we'll redefine our drawLane function\"\"\"\n",
    "\n",
    "slopeCut = 0.5 #student will change this value\n",
    "\n",
    "def drawLane(image, lines):\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                rise = y2 - y1\n",
    "                run = x2 - x1\n",
    "                if run != 0:\n",
    "                    slope = float(rise / run)\n",
    "                    if np.absolute(slope) > slopeCut:\n",
    "                        cv2.line(image,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "    return\n",
    "\n",
    "hough = blank(image)\n",
    "lines = houghLinesP(hough, focus)\n",
    "lineImage = cv2.bitwise_or(image, roi(hough))\n",
    "\n",
    "%matplotlib qt\n",
    "plt.imshow(lineImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115a38128>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"So, now we've got our lane lines identified, and we'd like to draw an estimate of where the \n",
    "lane is on the image.  To do this, fit a line to to all \n",
    "the detected line segments, and extrapolate up and \n",
    "down the road. Again, we'll redefine our \n",
    "drawLanes function\n",
    "and our houghLinesP to include one more parameter...\"\"\"\n",
    "\n",
    "#HERE I'M NOT SURE WHAT TO HAVE THE STUDENT DO, BUT MAYBE FIGURE OUT THEIR OWN WAY OF DRAWING THE LINES BETTER\n",
    "\n",
    "def houghLinesP(image, edges):\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 10 \n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,10,minLineLength,maxLineGap)\n",
    "    drawLane(image, lines)\n",
    "    return lines\n",
    "    \n",
    "def drawLane(image, lines):\n",
    "    \n",
    "    midpointx = round(float(image.shape[1])/2)\n",
    "    rightX = []\n",
    "    leftX = []\n",
    "    rightY = []\n",
    "    leftY = []\n",
    "       \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                rise = y2 - y1\n",
    "                run = x2 - x1\n",
    "                if run != 0:\n",
    "                    slope = float(rise / run)                \n",
    "                    if slope > slopeCut and x1 > midpointx and x2 > midpointx: \n",
    "                        #identifying lane line segments on the right side of the frame\n",
    "                        rightX.extend([x1, x2])\n",
    "                        rightY.extend([y1, y2])\n",
    "                    elif slope < -slopeCut and x1 < midpointx and x2 < midpointx: \n",
    "                        #identifying lane line segments on the left side of the frame\n",
    "                        leftX.extend([x1, x2])\n",
    "                        leftY.extend([y1, y2])                   \n",
    "\n",
    "        fitLeft = np.polyfit(leftX, leftY, 1)\n",
    "        startYleft = 0\n",
    "        endYleft = image.shape[0]\n",
    "        startXleft = int((startYleft - fitLeft[1]) / fitLeft[0])\n",
    "        endXleft = int((endYleft - fitLeft[1]) / fitLeft[0])\n",
    "\n",
    "        fitRight = np.polyfit(rightX, rightY, 1)\n",
    "        startYright = 0\n",
    "        endYright = image.shape[0]\n",
    "        startXright = int((startYright - fitRight[1]) / fitRight[0])\n",
    "        endXright = int((endYright - fitRight[1]) / fitRight[0])\n",
    "\n",
    "        cv2.line(image,(startXleft,startYleft),(endXleft,endYleft),(0,0,255),10)\n",
    "        cv2.line(image,(startXright,startYright),(endXright,endYright),(0,0,255),10)\n",
    "\n",
    "hough = blank(image)\n",
    "lines = houghLinesP(hough, focus)\n",
    "lineImage = cv2.bitwise_or(image, roi(hough))\n",
    "\n",
    "plt.imshow(lineImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Ok awesome!  We're mapping out the lane!  Now let's try it on a video stream. To do this, let's gather all \n",
    "the code into one place so this cell can be run independent of the rest of the notebook, or copied and pasted\n",
    "to somewhere else.\"\"\"\n",
    "\n",
    "#HERE AGAIN, NOT SURE WHAT TO HAVE THE STUDENT DO, BUT IF THIS IS AN EVALUATED PROJECT, THEY COULD SUBMIT\n",
    "#SUGGESTIONS ABOUT HOW TO IMPROVE THE ALGORITHM.  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib qt\n",
    "\n",
    "def color_select(image):\n",
    "    lower_white = np.array([165,165,165], dtype=np.uint8)\n",
    "    upper_white = np.array([245,245,245], dtype=np.uint8)\n",
    "    selected = cv2.inRange(image, lower_white, upper_white)\n",
    "    return selected\n",
    "\n",
    "def blank(image):\n",
    "    rows,cols = image.shape[:2]\n",
    "    if len(image.shape) == 2:\n",
    "        return np.zeros((rows, cols), np.uint8)\n",
    "    else:\n",
    "        return np.zeros((rows, cols, 3), np.uint8)\n",
    "\n",
    "def roi(image):\n",
    "    rows,cols = image.shape[:2]\n",
    "    copy = image.copy()\n",
    "    z = blank(image)\n",
    "    copy[:round(rows*0.4),:] = z[:round(rows*0.4),:]\n",
    "    return copy\n",
    "\n",
    "def houghLinesP(image, edges):\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 10 \n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,10,minLineLength,maxLineGap)\n",
    "    drawLane(image, lines)\n",
    "    return lines\n",
    "    \n",
    "def drawLane(image, lines):\n",
    "    \n",
    "    midpointx = round(float(image.shape[1])/2)\n",
    "    rightX = []\n",
    "    leftX = []\n",
    "    rightY = []\n",
    "    leftY = []\n",
    "       \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                rise = y2 - y1\n",
    "                run = x2 - x1\n",
    "                if run != 0:\n",
    "                    slope = float(rise / run)                \n",
    "                    if slope > slopeCut and x1 > midpointx and x2 > midpointx: \n",
    "                        #identifying lane line segments on the right side of the frame\n",
    "                        rightX.extend([x1, x2])\n",
    "                        rightY.extend([y1, y2])\n",
    "                    elif slope < -slopeCut and x1 < midpointx and x2 < midpointx: \n",
    "                        #identifying lane line segments on the left side of the frame\n",
    "                        leftX.extend([x1, x2])\n",
    "                        leftY.extend([y1, y2])                   \n",
    "\n",
    "        if leftX and leftY: \n",
    "            fitLeft = np.polyfit(leftX, leftY, 1)\n",
    "            startYleft = 0\n",
    "            endYleft = image.shape[0]\n",
    "            startXleft = int((startYleft - fitLeft[1]) / fitLeft[0])\n",
    "            endXleft = int((endYleft - fitLeft[1]) / fitLeft[0])\n",
    "            cv2.line(image,(startXleft,startYleft),(endXleft,endYleft),(0,0,255),10)\n",
    "            \n",
    "        if rightX and rightY:\n",
    "            fitRight = np.polyfit(rightX, rightY, 1)\n",
    "            startYright = 0\n",
    "            endYright = image.shape[0]\n",
    "            startXright = int((startYright - fitRight[1]) / fitRight[0])\n",
    "            endXright = int((endYright - fitRight[1]) / fitRight[0])\n",
    "            cv2.line(image,(startXright,startYright),(endXright,endYright),(0,0,255),10)\n",
    "\n",
    "                   \n",
    "cv2.startWindowThread()\n",
    "cv2.namedWindow('Lane-Finding')\n",
    "cap = cv2.VideoCapture('P0_video.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, image = cap.read()\n",
    "    if image is not None:\n",
    "        cselect = color_select(image)\n",
    "        focus = roi(cselect)\n",
    "        hough = blank(image)\n",
    "        houghLinesP(hough, focus)\n",
    "        final = cv2.bitwise_or(image, roi(hough))\n",
    "        cv2.imshow('Lane-Finding',final)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27 :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Fantastic!  It kinda works!  Clearly, however, our algorithm is still a bit unstable and could use \n",
    "further improvement.  So things to think about going forward are: how can we stabilize the lane detection \n",
    "further?  Where does it fail the worst?  What will we need to take into account going forward \n",
    "with lane detection?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
